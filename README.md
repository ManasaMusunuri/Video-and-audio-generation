AI-Powered Text-to-Video Generation

ğŸ“Œ Overview
This project generates AI-powered videos from text prompts using Stable Diffusion and MoviePy. It creates a sequence of images based on a given prompt, interpolates frames for smooth transitions, and compiles them into a video. Additionally, it supports text-to-audio conversion to generate voiceovers for the videos.


ğŸš€ Technologies Used
â€¢	Python (Primary language)
â€¢	Stable Diffusion (Image generation)
â€¢	OpenCV (Frame processing)
â€¢	NumPy (Mathematical operations)
â€¢	MoviePy (Video creation)
â€¢	gTTS (Google Text-to-Speech) (Audio generation)
â€¢	CUDA (For GPU acceleration, if available)
ğŸ› ï¸ Installation
1ï¸âƒ£ Clone the Repository
git clone https://github.com/yourusername/AI-Text-to-Video.git
cd AI-Text-to-Video
2ï¸âƒ£ Install Dependencies
pip install torch diffusers opencv-python numpy moviepy gtts
3ï¸âƒ£ Download the Stable Diffusion Model
from diffusers import StableDiffusionPipeline
import torch

model_id = "runwayml/stable-diffusion-v1-5"
pipeline = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)
pipeline.to("cuda")  # Use GPU if available
ğŸ¥ How It Works
1ï¸âƒ£ Image Generation
â€¢	The model generates multiple images based on the given text prompt.
â€¢	These images serve as frames for the video.
2ï¸âƒ£ Frame Interpolation
â€¢	OpenCV is used to smooth the transition between frames.
â€¢	Interpolation helps in creating a more natural animation.
3ï¸âƒ£ Video Compilation
â€¢	MoviePy compiles the interpolated frames into an MP4 video.
4ï¸âƒ£ Audio Generation
â€¢	gTTS generates speech from the text prompt.
â€¢	The generated audio is merged with the video.
ğŸ¬ Usage
Run the script with your custom text prompt:
python generate_video.py
Modify the prompt inside the script:
text_prompt = "How Artificial Intelligence works"

ğŸ”¥ Features
âœ… AI-generated videos from text prompts
âœ… Smooth frame transitions
âœ… Automatic voiceover generation
âœ… GPU acceleration support
ğŸ“Œ Future Enhancements
â€¢	Use advanced text-to-video models for more realistic animations.
â€¢	Implement real-time rendering with video diffusion models.
â€¢	Allow custom voice selection for text-to-speech.
â€¢	Integrate a user-friendly web interface.
________________________________________
ğŸ“Œ Contributor: Manasa 
ğŸ“Œ License: MIT
ğŸ“Œ GitHub Repository: AI-Text-to-Video

